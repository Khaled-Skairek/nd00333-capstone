{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used is the heart failure prediction dataset available at Kaggle.com.\n",
    "Each entry of the dataset conatins information (features) about individual. The task is binary classification; to predict if individual is going to have heart failure or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'AutoML_experiment'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "from azureml.core.compute_target import ComputeTargetException \n",
    "\n",
    "# Choose a name for your CPU cluster \n",
    "cpu_cluster_name = \"my-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already \n",
    "try: \n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.') \n",
    "except ComputeTargetException: \n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           max_nodes=4) \n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config) \n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='Heart-failure-prediction') \n",
    "dataset.to_pandas_dataframe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "### AutoMLSettings\n",
    "Due to the available resources (time and space), the auto ml is limited with timeout and maximum allowed parallel computations. The used metric for post-thresholding is  AUC_weighted which optimizes better for small datasets.\n",
    "\n",
    "### AutoMLConfig\n",
    "Since the task is classification, we need to provide the type, the dataset, and the labeled column (DEATH_EVENT). Early stopping is enabled to save time as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20, \n",
    "    \"max_concurrent_iterations\": 5, \n",
    "    \"primary_metric\" : 'AUC_weighted' \n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task=\"classification\", \n",
    "                             training_data=dataset,\n",
    "                             compute_target=cpu_cluster, \n",
    "                             label_column_name=\"DEATH_EVENT\",    \n",
    "                             path=\".\", \n",
    "                             enable_early_stopping=True, \n",
    "                             featurization='auto', \n",
    "                             debug_log=\"automl_errors.log\", \n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your experiment\n",
    "remote_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_run.wait_for_completion() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run, fitted_model = remote_run.get_output() \n",
    "print (best_run) \n",
    "print (fitted_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Save the best model\n",
    "joblib.dump(fitted_model, \"best_model_auto_ml.model\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\n",
    "\n",
    "model = Model.register(workspace=ws,\n",
    "                       model_name='my-autoML-model',                # Name of the registered model in your workspace.\n",
    "                       model_path='./best_model_auto_ml.model',     # Local file to upload and register as a model.\n",
    "                       resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5),\n",
    "                       description='VotingEnsemble') # ,\n",
    "                       # tags={'area': 'diabetes', 'type': 'classification'})\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core import Environment\n",
    "\n",
    "environment = Environment.get(workspace=ws, name=\"AzureML-AutoML\")\n",
    "service_name = 'heart-failure-prediction'\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=environment)\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1)\n",
    "service = Model.deploy(workspace=ws,\n",
    "                      name=service_name,\n",
    "                      models=[model],\n",
    "                      inference_config=inference_config,\n",
    "                      deployment_config=aci_config,\n",
    "                      overwrite=True)\n",
    "\n",
    "print(service.get_logs())\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL for the web service, should be similar to:\n",
    "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score'\n",
    "scoring_uri = service.scoring_uri\n",
    "# If the service is authenticated, set the key or token\n",
    "key = ''\n",
    "\n",
    "# Two sets of data to score, so we get two results back\n",
    "data = {\"data\":\n",
    "        [\n",
    "          {\n",
    "            \"age\": 17,\n",
    "            \"anaemia\": 1,\n",
    "            \"creatinine_phosphokinase\": 600,\n",
    "            \"diabetes\": 1,\n",
    "            \"ejection_fraction\": 30,\n",
    "            \"high_blood_pressure\": 0,\n",
    "            \"platelets\": 263000,\n",
    "            \"serum_creatinine\": 1.2,\n",
    "            \"serum_sodium\": 130,\n",
    "            \"sex\": 1,\n",
    "            \"smoking\": 0,\n",
    "            \"time\": 15,\n",
    "          },\n",
    "          {\n",
    "            \"age\": 35,\n",
    "            \"anaemia\": 0,\n",
    "            \"creatinine_phosphokinase\": 500,\n",
    "            \"diabetes\": 0,\n",
    "            \"ejection_fraction\": 30,\n",
    "            \"high_blood_pressure\": 0,\n",
    "            \"platelets\": 280000,\n",
    "            \"serum_creatinine\": 2.1,\n",
    "            \"serum_sodium\": 150,\n",
    "            \"sex\": 0,\n",
    "            \"smoking\": 0,\n",
    "            \"time\": 10,\n",
    "          },\n",
    "      ]\n",
    "    }\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "with open(\"data.json\", \"w\") as _f:\n",
    "    _f.write(input_data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "# headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "service.get_logs(num_lines=100)\n",
    "# service.delete()\n",
    "\n",
    "# AmlCompute.delete(cpu_cluster)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
